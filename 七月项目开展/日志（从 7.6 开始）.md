### 7.6

R 包调研

brenda 数据库调研

### 7.7

#### 需要问生物组的问题

natrual substrates 和 substrates 的区别是什么

commentary substrates 是什么意思，是不是专有名词

是不是一个 EC 编码对应很多种酶

能不能让用户先给出 EC 编码的前几位

**有没有别名到 SMILES 的数据库**

#### 技术方面到的问题与解决方案

- brenda 从酶到反应的数据库里有部分自然语言，处理起来不够方便

- **最好能找到规范化的、可以下载到本地的、能从酶找到它能催化的反应的数据库**

- brenda 下载的 txt 信息没有线上的 brenda 数据库全

- 访问 brenda 的方式- 直接查询（brenda 对直接查询的频率有限制，能否通过用户的浏览器发出查询请求） 或者 爬到本地

##### 初筛的步骤

用户给出反应类型、反应物、生成物与给定的基团，通过反应类型先筛选一部分酶（SELECT ... WHERE Reaction_type= ...，brenda 里能查每种 EC 编码能催化的反应类型）。

再通过查找反应物 SMILES 字符串内是否存在某个基团作进一步筛选（SELECT... WHERE SMILES...，brenda 里能查每中 EC 编码的底物，也可以查到该底物的 mol 文件），将筛选的EC编码作为初筛的结果。

通过 EC 编码可以直接查到它可以 催化的反应的唯一标识字符串。

建立从**别名**到**SMILES**的索引、从**反应物SMILES**到**能与之作用的EC 编码**的索引（索引都是sql，第二个索引带反应类型、反应的唯一标识字符串的字段）

### 7.8

将 brenda 的搜索内容调为 Enzyme,Ligand 以后，在搜索栏内输入酶底物的名称（如 (R)-2-butanol），就可以搜到相关的信息，并且可以下载底物的 mol 文件，如下图所示。mol 文件可以通过 python 的 rdkit 包转化为 SMILES。产物同理可以获得 mol 文件。

### 7.9

进一步确定的技术路线：

==在 mysql 中，为每个 Reaction Type 建一个 table，table 中的每一项以 EC 编码作为主码（一列）。==

==另外还需要一个 table，里面包含了 酶的 EC 编码 到 Reaction String 和 相应的底物 SMILES。（三列）==

完成对所有 EC 编码的爬取。

已经实现 Reaction Type 的统计。

同时开始进行对 每种 EC 编码及其对应的底物和相应产物的数据 的爬取。

### 7.10

可以爬取特定名称的有机物的 mol 文件信息（通过 selenium 实现），但是需要先获得 EC 编码的底物和产物的数据才能进一步爬取。

两台 vlab 虚拟机在跑爬虫（10-15s 一个 csv 文件，访问过于频繁 IP 可能被封），目前童蒙申请的那台已爬完 EC 编码 3.5.1.1 之后共 2070 种酶的数据，还在爬 EC 编码在 3.1.1.1 到 3.4.99.46 共 1409 种酶的数据。

注意：在爬取信息的时候注释 additionnal information 也会被放到 csv 文件里。

已经建好 不同反应类型的 EC 编码 的数据库。

### 7.11

已经爬完所有 EC 编码的底物和产物信息并作好处理。

实现 chrome 上 mol 文件的自动化下载。

### 7.12

实现 Firefox 上 mol 文件的自动化下载，进一步将其部署在 vlab 的虚拟机上。

共 262385 行数据，其中每 50000 行的分界点如下。

- 1-14-14-51 50019 tjf
- 2-4-1-129 100012 tm 17:13 重启（此时有 700 多条数据）
- 3-1-1-72 150102 xa 15:30 开始运行
- 3-4-22-15 200091 pyx 14:56 开始运行
- 6-2-1-40 250017 本地在运行（17:00开始运行）

​ 因此以这五个为分界点分成了六段 ec 文件以进行分布式爬取。

今晚记得把程序重启一遍。（有关异常处理的问题）

现在下载 mol 文件的时候会出现有些有机物的 mol 文件没有下载下来的情况，有可能是 brenda 上没有它的 mol 文件，也有可能是下载的时候出现网络波动导致连接超时引发异常。

为区分这两种情况，初步的处理方式是在将 ec_sub_pro.txt 中的名称转成 SMILES 的时候，对于没有找到对应的 SMILES 的名称，再单独形成一份文件统一爬取，最终还没有下到 mol 文件的有机物将被认为是 mol 文件未被 brenda 给出的有机物。

下好 mol 文件后，需要程序将这些 mol 批量转成 SMILES，并在一个文件内以 “名称 + SMILES” 存储下来。再通过 ec_sub_pro 文件在一个文件中以 “ EC 编码 + 反应物 SMILES + 生成物 SMILES + 反应 SMILES” 的形式存下每一种酶的催化信息。在此基础上建立 MySQL 数据库

预计在 7 月 20 日（周三）之前做出第一版的 demo

总体的步骤：

1. 建好所需的 MySQL 数据库
2. 写核心代码（初筛 MySQL + r 包运算 + 结果输出）
3. 写后端代码（django rest framework）
4. 测试、优化、部署到服务器上

### 7.13

爬虫存在问题，下载的时候会

修改爬虫代码，并重开所有服务器（时间十一点半，共 tjf、tm、xa、pyx 四台服务器）

四点重启所有电脑（将计时的 time.clock(从 python3.8 开始失效)，改成 time.process_time）

爬虫问题很大，明天早上再看看，实在不行就开会解决，先去看核心代码的部分，数据什么的后面再说。

先跑一个晚上，明天早上看看问题出在哪里。

### 7.14

修改爬虫代码，分发 vlab 虚拟机，正式开始爬取信息。

### 7.15

写完各部分的核心代码

### 7.16

- 开始拼接核心代码，做出极简的 demo；

- 重写爬虫（原先的爬虫仍然存在问题）；

- 修改 SubPro 文件

### 7.17

- 修改爬虫代码

- 将后端项目移植到 ubuntu 上

- 调研后端项目的部署（wsgi、nginx）

### 7.18

- 完成后端项目的移植，尝试使用 ray 优化，但是虚拟机卡死（打算先试试虚拟机上能否正常运行 ray）

- 尝试使用多线程优化，有一定效果，但是稳定性变差（单线程比对 500 条在 10 秒左右，多线程比对 500 条的结果在 8 秒左右）

- 调研后端项目的部署

- 与生物组合作尝试解决初筛问题

### 7.19

- 成功在 Windows 上搭建起 ray 集群进行相似度的计算，计算相似度的时间下降，但是网络传输时间上升，导致总延迟升高。
- 初步判断是因为 ray 和后端 api 跑在同一台机子上，ray 的计算占用了过多资源，比对时间变短，但是比对完以后恢复其他进程的时间大幅提升，后端 api 的传输效率大幅下降。考虑将后端 api 的功能和 ray 的功能分离，采用 WebSockets 通信来提升效率。
- 尝试使用 rpc 来分离这二者的功能

### 7.20

- 通过 rpc 完成后端 api 和 ray 计算集群的分离

- 开始爬取 mol 文件

- 生物组提供有机物基团相关信息

### 7.21-7.22

- 因搬寝室暂停

### 7.23

- 做了一个基础的性能测试（比对 512 条）
  
  在本地机子上跑（四核，api 和比对在一起）
  
  | 比对方式    | 比对延迟      |
  | ------- | --------- |
  | 普通比对    | 6-10 s    |
  | ray 单线程 | 12 - 14 s |
  | ray 双线程 | 12 - 14 s |
  | ray 四线程 | 9-13 s    |
  | ray 八线程 | 13 - 15 s |
  
  在服务器上跑（双核，api 通过 rpc 调用比对模块）
  
  | 比对方式    | 比对延迟    |
  | ------- | ------- |
  | 普通比对    | 25-30 s |
  | ray 单线程 | 11-12 s |
  | ray 双线程 | 12-13 s |
  | ray 四线程 | 18 s 左右 |
  
  目前的计划：租一台 4 核 或者 8 核的服务器去进行 ray 的计算，并在初筛时尽量缩小需 要比对的规模，以降低后端 api 的延时

- 将生物组提供的基团结构式手动转化成 smiles 格式，并思考初筛时如何判断某个基团是否属于某个有机物

- 得到了一部分 ec 编码与其底物、产物、反应 smiles 对应的关系，准备建立最终的反应数据库

- 考虑后端 api 的正式部署，以及与前端进行拼接

### 7.24

- 利用 rdkit 完成初筛部分

- 完成大部分的 mysql 数据库的建立

- 准备优化

- 性能测试：ray 开双线程运行
  
  - 第一组测试样例在 9805 份数据中筛选出 23 份，初筛时间为 2.5s，比对时间为 3.9s，算上 rpc 传输时间的比对时间为 4.3s
  
  - 第二组测试样例在 9805 份数据中筛选出 5853 份，初筛时间为 2.75s，比对时间为 92.5s，算上 rpc 传输时间的比对时间为 92.9s

### 7.25

- 完成 mysql 数据库的建立（除了部分异常数据）

- 通过 RxnSim 的参数选择实现一部分优化（原先第二组样例 90s -> 60s）

- 删去 MySQL 数据库中被截断的反应

- 通过删去初筛后的相同反应，实现一部分优化（原先第二组样例 60s -> 46s）

- 完成前后端的交互

- 返回信息还需添加酶的链接和名称

### 7.26

- 当前性能：原先第二组样例从一万份左右的数据中初筛出 4000 份，比对时间 43s（其中 RxnSim 的计算时间 41s，ray 初始化时间 0.5s，导入 r 包 RxnSim 的时间 0.5s，等待 ray 执行完的时间 1s，由于是单线程在跑，无上下文切换时间），初筛时间 2.5s，总响应时间 45.5s

- 当前最优性能的 r 包参数（param = {'fpCached':True, 'algo':'rsim', 'fp.type':'standard', 'fp.size':1024}）

- 完成酶的 ec 编码与名称对应关系的爬取

- 暑假最好需要完成的事情：
  
  - 再了解一下 ray 或者其他并行计算框架，看看能不能通过分布式进行进一步优化；
  
  - 浅学一下 r 语言，看看 RxnSim 有没有什么优化空间；
  
  - 完成用户注册、登录、历史记录查询等后端 api 的实现